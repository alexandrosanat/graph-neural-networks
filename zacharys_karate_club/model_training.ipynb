{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911bf6a1-764e-460c-8c0c-20be6f07b7e0",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning with Spectral Graph Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7424b0a-67f7-4522-b514-ed46ba89038b",
   "metadata": {},
   "source": [
    "### Load Zachary's Karate Club data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5c0da8d1-d629-4cac-ae81-4a0200062597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f28c0649-9bab-4e2e-8f33-919ab3a390a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Load data into a networkx graph\n",
    "    '''\n",
    "\n",
    "    network = nx.read_edgelist(\n",
    "        'data/zkc.edgelist',\n",
    "        nodetype=int\n",
    "        )\n",
    "    \n",
    "    attributes = pd.read_csv(\n",
    "        'data/features.csv',\n",
    "        index_col=['node']\n",
    "        )\n",
    "\n",
    "    \n",
    "    for attribute in attributes.columns.values:\n",
    "        nx.set_node_attributes(\n",
    "                network,\n",
    "                values=pd.Series(\n",
    "                    attributes[attribute],\n",
    "                    index=attributes.index).to_dict(),\n",
    "                name=attribute\n",
    "            )\n",
    "\n",
    "    # Create a mask of all the train samples\n",
    "    # We will only use the Administrator and the Instructor but none of the members\n",
    "    train_mask = [True if attribute in ['Administrator', 'Instructor'] else False for attribute in attributes['role']]\n",
    "    test_mask = [True if item is False else False for item in train_mask]   \n",
    "\n",
    "    return train_mask, test_mask, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fddf38df-3eed-462e-8676-dc8af5812da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask, test_mask, network = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bb3c3a21-4fa8-42d4-a9cd-f1fcc3bb6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Label categories\n",
    "attributes['community'] = attributes['community'].astype('category')\n",
    "attributes['community'] = attributes['community'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9a06fcc9-3cc2-4db4-b619-87ed2906ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjacency matrix\n",
    "adj = nx.to_numpy_array(zkc.network)\n",
    "adj += np.eye(adj.shape[0])\n",
    "# First, we will only use the identity matrix as the only feature\n",
    "features = np.eye(adj.shape[0])\n",
    "\n",
    "# Labels\n",
    "labels = attributes['community'].values\n",
    "labels = labels.reshape(34, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "04d604d5-7216-4601-96dd-ba76b3d05981",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.astype('float32')\n",
    "adj = adj.astype('float32')\n",
    "labels = labels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "14318481-9549-4805-a2b2-cd753804fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    '''Applies loss function taking into account the mask to\n",
    "       only take into account relevant nodes.\n",
    "       Returns cross entropy loss over the masked nodes of the graph.'''\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    # Divide mask by its average value - that will enable us to take the product of the mask with the loss\n",
    "    mask /= tf.reduce_mean(mask)  # Is this step used to normalise?\n",
    "    loss *= mask\n",
    "    # return average across all positions\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    '''Returns accuracy over the masked nodes of the graph.'''\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d38f0bb4-206e-46b6-adcb-2b4a501ebf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    '''\n",
    "    Define a Graph Neural Network layer.\n",
    "    fts: node feature matrix\n",
    "    adj: adjacency matrix\n",
    "    transform: some transformation that we wish to apply to each node\n",
    "    activation: activation function\n",
    "    '''\n",
    "    # Transform each node \n",
    "    seq_fts = transform(fts)\n",
    "    # Once we have the features we want to aggregate we multiply by the adjacency matrix\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "678a6301-f917-4471-9083-13cf840f72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    '''Define simple 2 layer GNN.\n",
    "       gnn_fn: gnn model function\n",
    "       units: how many units we want our NN to compute in each node - \n",
    "              how many dimentions in our latent features.'''\n",
    "    lyr_1 = tf.keras.layers.Dense(units)\n",
    "    # Computes classification of nodes\n",
    "    lyr_2 = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def cora_gnn(fts, adj):\n",
    "        ''' Define the GNN that is used to solve this problem\n",
    "            on a specific set of features and adjacencies.'''\n",
    "        # Computes hidden features in every node\n",
    "        hidden = gnn_fn(fts, adj, lyr_1, tf.nn.relu)\n",
    "        logits = gnn_fn(hidden, adj, lyr_2, tf.identity)  # We don't need any further transformation so we use the identity matrix as activation\n",
    "        return logits\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs+1):\n",
    "        # Use tape to keep track of gradients \n",
    "        with tf.GradientTape() as t:\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "            \n",
    "        # Look at variables that gradient tape is watching\n",
    "        variables = t.watched_variables()  # Get variables\n",
    "        grads = t.gradient(loss, variables)  # Get gradients\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, variables))  # Apply gradients\n",
    "        \n",
    "        # Track val and test accuracy\n",
    "        logits = cora_gnn(fts, adj)  # Take logits after gradients have been updated\n",
    "        # val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "        \n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            print('Epoch', ep, '| Training Loss:', loss.numpy(),\n",
    "                  '|Test accuracy:', test_accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "961ed28b-cf69-4519-a6d8-53d8d46a2c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 0.0 |Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "hidden_features = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_model(features, adj, gnn, hidden_features, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfe132-b884-476d-819e-a1cf6e03c58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
