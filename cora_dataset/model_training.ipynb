{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bac7f7-12cd-4af6-b686-532f24cfb0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import spektral\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e17533-7dbe-4dfb-9055-bd0094d554fe",
   "metadata": {},
   "source": [
    "Load and pre-process graph representation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cd1e20-288c-4b97-a4ec-8873afa8e72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset\n",
      "Pre-processing node features\n"
     ]
    }
   ],
   "source": [
    "adj, features, labels, train_mask, val_mask, test_mask = spektral.datasets.citation.load_data(dataset_name='cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "692b68fe-aeb7-4173-bd09-2361c20fcfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708 nodes\n",
      "1433 features in every node\n",
      "7 classes\n",
      "140 training nodes\n",
      "500 validation nodes\n",
      "1000 test nodes\n"
     ]
    }
   ],
   "source": [
    "features = features.todense()\n",
    "# The adjacency matric doesn't come with self edges so we need to add the identity matrix \n",
    "adj = adj.todense() + np.eye(adj.shape[0])\n",
    "features = features.astype('float32')\n",
    "adj = adj.astype('float32')\n",
    "labels = labels.astype('float32')\n",
    "\n",
    "print(features.shape[0], 'nodes')\n",
    "print(features.shape[1], 'features in every node')\n",
    "print(labels.shape[1], 'classes')\n",
    "\n",
    "print(np.sum(train_mask), 'training nodes')\n",
    "print(np.sum(val_mask), 'validation nodes')\n",
    "print(np.sum(test_mask), 'test nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06a851e2-c053-498e-aa88-941ad888dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    '''Applies loss function taking into account the mask to\n",
    "       only take into account relevant nodes.\n",
    "       Returns cross entropy loss over the masked nodes of the graph.'''\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    # Divide mask by its average value - that will enable us to take the product of the mask with the loss\n",
    "    mask /= tf.reduce_mean(mask)  # Is this step used to normalise?\n",
    "    loss *= mask\n",
    "    # return average across all positions\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    '''Returns accuracy over the masked nodes of the graph.'''\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ad83f4e-5aa4-466c-adce-2be95ed98ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    '''\n",
    "    Define a Graph Neural Network layer.\n",
    "    fts: node feature matrix\n",
    "    adj: adjacency matrix\n",
    "    transform: some transformation that we wish to apply to each node\n",
    "    activation: activation function\n",
    "    '''\n",
    "    # Transform each node \n",
    "    seq_fts = transform(fts)\n",
    "    # Once we have the features we want to aggregate we multiply by the adjacency matrix\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dcf2190-922b-44fa-a3de-7c4e467e2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    '''Define simple 2 layer GNN.\n",
    "       gnn_fn: gnn model function\n",
    "       units: how many units we want our NN to compute in each node - \n",
    "              how many dimentions in our latent features.'''\n",
    "    lyr_1 = tf.keras.layers.Dense(units)\n",
    "    # Computes classification of nodes\n",
    "    lyr_2 = tf.keras.layers.Dense(7)\n",
    "    \n",
    "    def cora_gnn(fts, adj):\n",
    "        ''' Define the GNN that is used to solve this problem\n",
    "            on a specific set of features and adjacencies.'''\n",
    "        # Computes hidden features in every node\n",
    "        hidden = gnn_fn(fts, adj, lyr_1, tf.nn.relu)\n",
    "        logits = gnn_fn(hidden, adj, lyr_2, tf.identity)  # We don't need any further transformation so we use the identity matrix as activation\n",
    "        return logits\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs+1):\n",
    "        # Use tape to keep track of gradients \n",
    "        with tf.GradientTape() as t:\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "            \n",
    "        # Look at variables that gradient tape is watching\n",
    "        variables = t.watched_variables()  # Get variables\n",
    "        grads = t.gradient(loss, variables)  # Get gradients\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, variables))  # Apply gradients\n",
    "        \n",
    "        # Track val and test accuracy\n",
    "        logits = cora_gnn(fts, adj)  # Take logits after gradients have been updated\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training Loss:', loss.numpy(), '|Val accuracy:',\n",
    "                  val_accuracy.numpy(), '|Test accuracy:', test_accuracy.numpy())\n",
    "            \n",
    "    return cora_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69cc84e6-9f64-40a7-b956-44f58cb3ea97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 1.969773 |Val accuracy: 0.19399999 |Test accuracy: 0.19899999\n",
      "Epoch 1 | Training Loss: 1.9085302 |Val accuracy: 0.25199997 |Test accuracy: 0.24199998\n",
      "Epoch 2 | Training Loss: 1.5839084 |Val accuracy: 0.26 |Test accuracy: 0.268\n",
      "Epoch 3 | Training Loss: 1.4373523 |Val accuracy: 0.71199995 |Test accuracy: 0.738\n",
      "Epoch 4 | Training Loss: 1.1906141 |Val accuracy: 0.72999996 |Test accuracy: 0.749\n",
      "Epoch 5 | Training Loss: 1.1051586 |Val accuracy: 0.73399997 |Test accuracy: 0.746\n",
      "Epoch 6 | Training Loss: 1.0439419 |Val accuracy: 0.73999995 |Test accuracy: 0.747\n",
      "Epoch 14 | Training Loss: 0.4841191 |Val accuracy: 0.74799997 |Test accuracy: 0.7569999\n",
      "Epoch 15 | Training Loss: 0.44554722 |Val accuracy: 0.75399995 |Test accuracy: 0.76599985\n",
      "Epoch 16 | Training Loss: 0.41409317 |Val accuracy: 0.762 |Test accuracy: 0.76999986\n",
      "Epoch 17 | Training Loss: 0.38092667 |Val accuracy: 0.77199996 |Test accuracy: 0.76799995\n",
      "Epoch 21 | Training Loss: 0.27847943 |Val accuracy: 0.7720001 |Test accuracy: 0.77399987\n",
      "Epoch 25 | Training Loss: 0.20368809 |Val accuracy: 0.774 |Test accuracy: 0.76999986\n",
      "Epoch 26 | Training Loss: 0.1889371 |Val accuracy: 0.7819999 |Test accuracy: 0.7689999\n",
      "Epoch 36 | Training Loss: 0.08665722 |Val accuracy: 0.784 |Test accuracy: 0.7679999\n",
      "Epoch 43 | Training Loss: 0.05167393 |Val accuracy: 0.7859999 |Test accuracy: 0.7729999\n"
     ]
    }
   ],
   "source": [
    "hidden_features = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_cora(features, adj, gnn, hidden_features, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b89deec-6e01-45c7-8ff5-b557a60c4b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 1.9450082 |Val accuracy: 0.16599998 |Test accuracy: 0.20699999\n",
      "Epoch 1 | Training Loss: 1.9298187 |Val accuracy: 0.21999998 |Test accuracy: 0.272\n",
      "Epoch 2 | Training Loss: 1.9091934 |Val accuracy: 0.294 |Test accuracy: 0.36200002\n",
      "Epoch 3 | Training Loss: 1.8837721 |Val accuracy: 0.364 |Test accuracy: 0.406\n",
      "Epoch 4 | Training Loss: 1.8545489 |Val accuracy: 0.36999997 |Test accuracy: 0.419\n",
      "Epoch 5 | Training Loss: 1.8226416 |Val accuracy: 0.38799998 |Test accuracy: 0.42799997\n",
      "Epoch 6 | Training Loss: 1.787902 |Val accuracy: 0.39399996 |Test accuracy: 0.425\n",
      "Epoch 22 | Training Loss: 0.95110416 |Val accuracy: 0.41799998 |Test accuracy: 0.442\n",
      "Epoch 23 | Training Loss: 0.8916823 |Val accuracy: 0.42399997 |Test accuracy: 0.45199996\n",
      "Epoch 24 | Training Loss: 0.8331007 |Val accuracy: 0.42999998 |Test accuracy: 0.45799997\n",
      "Epoch 25 | Training Loss: 0.77563894 |Val accuracy: 0.436 |Test accuracy: 0.45899996\n",
      "Epoch 26 | Training Loss: 0.719587 |Val accuracy: 0.444 |Test accuracy: 0.465\n",
      "Epoch 27 | Training Loss: 0.6652217 |Val accuracy: 0.45 |Test accuracy: 0.472\n",
      "Epoch 28 | Training Loss: 0.6129041 |Val accuracy: 0.45999998 |Test accuracy: 0.47999993\n",
      "Epoch 29 | Training Loss: 0.5627633 |Val accuracy: 0.466 |Test accuracy: 0.48299995\n",
      "Epoch 30 | Training Loss: 0.51506 |Val accuracy: 0.474 |Test accuracy: 0.48299995\n",
      "Epoch 34 | Training Loss: 0.35136366 |Val accuracy: 0.47599998 |Test accuracy: 0.48899996\n",
      "Epoch 35 | Training Loss: 0.3175648 |Val accuracy: 0.482 |Test accuracy: 0.49099997\n",
      "Epoch 36 | Training Loss: 0.28657317 |Val accuracy: 0.49199998 |Test accuracy: 0.494\n",
      "Epoch 37 | Training Loss: 0.2582939 |Val accuracy: 0.494 |Test accuracy: 0.496\n",
      "Epoch 40 | Training Loss: 0.18843754 |Val accuracy: 0.496 |Test accuracy: 0.5\n",
      "Epoch 42 | Training Loss: 0.15280475 |Val accuracy: 0.50200003 |Test accuracy: 0.503\n",
      "Epoch 47 | Training Loss: 0.09236678 |Val accuracy: 0.504 |Test accuracy: 0.50200003\n",
      "Epoch 48 | Training Loss: 0.08399484 |Val accuracy: 0.50600004 |Test accuracy: 0.504\n",
      "Epoch 66 | Training Loss: 0.02388763 |Val accuracy: 0.508 |Test accuracy: 0.503\n",
      "Epoch 73 | Training Loss: 0.017831435 |Val accuracy: 0.51000005 |Test accuracy: 0.507\n",
      "Epoch 74 | Training Loss: 0.017206587 |Val accuracy: 0.512 |Test accuracy: 0.507\n",
      "Epoch 75 | Training Loss: 0.016624685 |Val accuracy: 0.51799995 |Test accuracy: 0.507\n",
      "Epoch 127 | Training Loss: 0.006142541 |Val accuracy: 0.518 |Test accuracy: 0.504\n"
     ]
    }
   ],
   "source": [
    "hidden_features = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Is it useful to use the graph?\n",
    "# Test by changing the adjacency matrix with the identity matrix (standard point-wise MLP model)\n",
    "train_cora(features, tf.eye(adj.shape[0]), gnn, hidden_features, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17230f47-f0a0-4038-9182-3b8087922558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 1.9451618 |Val accuracy: 0.121999994 |Test accuracy: 0.134\n",
      "Epoch 3 | Training Loss: 1.8901854 |Val accuracy: 0.12799999 |Test accuracy: 0.147\n",
      "Epoch 4 | Training Loss: 1.8675568 |Val accuracy: 0.14199999 |Test accuracy: 0.171\n",
      "Epoch 5 | Training Loss: 1.8443671 |Val accuracy: 0.17799999 |Test accuracy: 0.19999999\n",
      "Epoch 6 | Training Loss: 1.8197027 |Val accuracy: 0.218 |Test accuracy: 0.234\n",
      "Epoch 7 | Training Loss: 1.7928916 |Val accuracy: 0.25599998 |Test accuracy: 0.26900002\n",
      "Epoch 8 | Training Loss: 1.7637992 |Val accuracy: 0.304 |Test accuracy: 0.30900002\n",
      "Epoch 9 | Training Loss: 1.7324904 |Val accuracy: 0.36399996 |Test accuracy: 0.37199998\n",
      "Epoch 10 | Training Loss: 1.6993543 |Val accuracy: 0.41600004 |Test accuracy: 0.429\n",
      "Epoch 11 | Training Loss: 1.6652437 |Val accuracy: 0.486 |Test accuracy: 0.49199998\n",
      "Epoch 12 | Training Loss: 1.6295828 |Val accuracy: 0.544 |Test accuracy: 0.553\n",
      "Epoch 13 | Training Loss: 1.592213 |Val accuracy: 0.59 |Test accuracy: 0.605\n",
      "Epoch 14 | Training Loss: 1.5531906 |Val accuracy: 0.63600004 |Test accuracy: 0.63\n",
      "Epoch 15 | Training Loss: 1.5126432 |Val accuracy: 0.652 |Test accuracy: 0.66300005\n",
      "Epoch 16 | Training Loss: 1.4707415 |Val accuracy: 0.676 |Test accuracy: 0.69200003\n",
      "Epoch 17 | Training Loss: 1.4275622 |Val accuracy: 0.684 |Test accuracy: 0.715\n",
      "Epoch 18 | Training Loss: 1.38323 |Val accuracy: 0.69200003 |Test accuracy: 0.731\n",
      "Epoch 19 | Training Loss: 1.3379322 |Val accuracy: 0.7 |Test accuracy: 0.742\n",
      "Epoch 20 | Training Loss: 1.291895 |Val accuracy: 0.722 |Test accuracy: 0.75499994\n",
      "Epoch 21 | Training Loss: 1.2453346 |Val accuracy: 0.73399997 |Test accuracy: 0.76599985\n",
      "Epoch 22 | Training Loss: 1.1984366 |Val accuracy: 0.742 |Test accuracy: 0.7759999\n",
      "Epoch 23 | Training Loss: 1.1513709 |Val accuracy: 0.758 |Test accuracy: 0.78299993\n",
      "Epoch 25 | Training Loss: 1.0572971 |Val accuracy: 0.762 |Test accuracy: 0.79499984\n",
      "Epoch 26 | Training Loss: 1.0106735 |Val accuracy: 0.76600003 |Test accuracy: 0.79499984\n",
      "Epoch 33 | Training Loss: 0.7080778 |Val accuracy: 0.77199996 |Test accuracy: 0.8149998\n",
      "Epoch 34 | Training Loss: 0.66977006 |Val accuracy: 0.77599996 |Test accuracy: 0.8149998\n",
      "Epoch 35 | Training Loss: 0.6329535 |Val accuracy: 0.78 |Test accuracy: 0.8159998\n",
      "Epoch 36 | Training Loss: 0.59767616 |Val accuracy: 0.782 |Test accuracy: 0.8149998\n",
      "Epoch 37 | Training Loss: 0.5639583 |Val accuracy: 0.784 |Test accuracy: 0.8149998\n",
      "Epoch 39 | Training Loss: 0.50123405 |Val accuracy: 0.7859999 |Test accuracy: 0.8159998\n"
     ]
    }
   ],
   "source": [
    "hidden_features = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Since the graph is useful we can explore mean pooling\n",
    "# Calculate the degree matrix\n",
    "deg = tf.reduce_sum(adj, axis=-1)  # Compute the degree matrix as the degree of each node and then spread across the diagonal\n",
    "train_cora(features, adj/deg, gnn, hidden_features, epochs, learning_rate)  # This will give us a normalised propagation rule which should deal with any exploding signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13aa1e20-6ac1-429e-906a-e50896afd350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 1.9457494 |Val accuracy: 0.252 |Test accuracy: 0.22399999\n",
      "Epoch 1 | Training Loss: 1.936319 |Val accuracy: 0.258 |Test accuracy: 0.248\n",
      "Epoch 6 | Training Loss: 1.8478409 |Val accuracy: 0.27199998 |Test accuracy: 0.27699998\n",
      "Epoch 7 | Training Loss: 1.8239292 |Val accuracy: 0.318 |Test accuracy: 0.306\n",
      "Epoch 8 | Training Loss: 1.7981963 |Val accuracy: 0.358 |Test accuracy: 0.34600002\n",
      "Epoch 9 | Training Loss: 1.77068 |Val accuracy: 0.408 |Test accuracy: 0.377\n",
      "Epoch 10 | Training Loss: 1.7411994 |Val accuracy: 0.446 |Test accuracy: 0.41799998\n",
      "Epoch 11 | Training Loss: 1.7096944 |Val accuracy: 0.464 |Test accuracy: 0.46099997\n",
      "Epoch 12 | Training Loss: 1.6762741 |Val accuracy: 0.516 |Test accuracy: 0.501\n",
      "Epoch 13 | Training Loss: 1.6409322 |Val accuracy: 0.566 |Test accuracy: 0.559\n",
      "Epoch 14 | Training Loss: 1.6037468 |Val accuracy: 0.618 |Test accuracy: 0.60999995\n",
      "Epoch 15 | Training Loss: 1.5648412 |Val accuracy: 0.648 |Test accuracy: 0.64599997\n",
      "Epoch 16 | Training Loss: 1.5243117 |Val accuracy: 0.668 |Test accuracy: 0.662\n",
      "Epoch 17 | Training Loss: 1.4822407 |Val accuracy: 0.682 |Test accuracy: 0.68\n",
      "Epoch 18 | Training Loss: 1.4386673 |Val accuracy: 0.69200003 |Test accuracy: 0.686\n",
      "Epoch 19 | Training Loss: 1.3937128 |Val accuracy: 0.714 |Test accuracy: 0.70399994\n",
      "Epoch 20 | Training Loss: 1.347534 |Val accuracy: 0.722 |Test accuracy: 0.719\n",
      "Epoch 21 | Training Loss: 1.3003215 |Val accuracy: 0.736 |Test accuracy: 0.733\n",
      "Epoch 22 | Training Loss: 1.2522392 |Val accuracy: 0.74599993 |Test accuracy: 0.74399996\n",
      "Epoch 23 | Training Loss: 1.203473 |Val accuracy: 0.756 |Test accuracy: 0.75799996\n",
      "Epoch 24 | Training Loss: 1.1542274 |Val accuracy: 0.75999993 |Test accuracy: 0.76100004\n",
      "Epoch 25 | Training Loss: 1.1047206 |Val accuracy: 0.766 |Test accuracy: 0.7639999\n",
      "Epoch 26 | Training Loss: 1.0551685 |Val accuracy: 0.778 |Test accuracy: 0.7709999\n",
      "Epoch 27 | Training Loss: 1.0057607 |Val accuracy: 0.782 |Test accuracy: 0.7749999\n",
      "Epoch 28 | Training Loss: 0.9567175 |Val accuracy: 0.7839999 |Test accuracy: 0.7819999\n"
     ]
    }
   ],
   "source": [
    "norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
    "norm_adj = tf.matmul(norm_deg, tf.matmul(adj, norm_deg))\n",
    "train_cora(features, norm_adj, gnn, hidden_features, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d267a4a-8824-4b54-8702-e87dc53b3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training Loss: 1.9456286 |Val accuracy: 0.19799998 |Test accuracy: 0.226\n",
      "Epoch 1 | Training Loss: 1.9365743 |Val accuracy: 0.26 |Test accuracy: 0.273\n",
      "Epoch 2 | Training Loss: 1.9250264 |Val accuracy: 0.266 |Test accuracy: 0.26099998\n",
      "Epoch 3 | Training Loss: 1.9087073 |Val accuracy: 0.284 |Test accuracy: 0.27299997\n",
      "Epoch 4 | Training Loss: 1.8908659 |Val accuracy: 0.322 |Test accuracy: 0.325\n",
      "Epoch 5 | Training Loss: 1.8715485 |Val accuracy: 0.35599998 |Test accuracy: 0.38000003\n",
      "Epoch 6 | Training Loss: 1.850498 |Val accuracy: 0.38599998 |Test accuracy: 0.41400003\n",
      "Epoch 7 | Training Loss: 1.8279786 |Val accuracy: 0.42199996 |Test accuracy: 0.442\n",
      "Epoch 8 | Training Loss: 1.803438 |Val accuracy: 0.45 |Test accuracy: 0.47\n",
      "Epoch 9 | Training Loss: 1.7769442 |Val accuracy: 0.50200003 |Test accuracy: 0.49499997\n",
      "Epoch 10 | Training Loss: 1.7488081 |Val accuracy: 0.524 |Test accuracy: 0.519\n",
      "Epoch 11 | Training Loss: 1.7188131 |Val accuracy: 0.562 |Test accuracy: 0.555\n",
      "Epoch 12 | Training Loss: 1.6868143 |Val accuracy: 0.594 |Test accuracy: 0.598\n",
      "Epoch 13 | Training Loss: 1.6530495 |Val accuracy: 0.636 |Test accuracy: 0.63900006\n",
      "Epoch 14 | Training Loss: 1.6177111 |Val accuracy: 0.664 |Test accuracy: 0.673\n",
      "Epoch 15 | Training Loss: 1.5808096 |Val accuracy: 0.696 |Test accuracy: 0.694\n",
      "Epoch 16 | Training Loss: 1.5423166 |Val accuracy: 0.716 |Test accuracy: 0.716\n",
      "Epoch 17 | Training Loss: 1.5021684 |Val accuracy: 0.726 |Test accuracy: 0.734\n",
      "Epoch 18 | Training Loss: 1.460287 |Val accuracy: 0.738 |Test accuracy: 0.75399995\n",
      "Epoch 19 | Training Loss: 1.4165788 |Val accuracy: 0.75200003 |Test accuracy: 0.7639999\n",
      "Epoch 20 | Training Loss: 1.3713826 |Val accuracy: 0.76199996 |Test accuracy: 0.7759999\n",
      "Epoch 21 | Training Loss: 1.3253279 |Val accuracy: 0.76399994 |Test accuracy: 0.7769999\n",
      "Epoch 22 | Training Loss: 1.2785711 |Val accuracy: 0.76799995 |Test accuracy: 0.7789999\n",
      "Epoch 23 | Training Loss: 1.2310928 |Val accuracy: 0.77599996 |Test accuracy: 0.7859999\n",
      "Epoch 24 | Training Loss: 1.1830626 |Val accuracy: 0.7839999 |Test accuracy: 0.7879999\n",
      "Epoch 62 | Training Loss: 0.12643994 |Val accuracy: 0.784 |Test accuracy: 0.7919999\n"
     ]
    }
   ],
   "source": [
    "model = train_cora(features, norm_adj, gnn, hidden_features, epochs, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
